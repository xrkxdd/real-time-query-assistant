import streamlit as st
import google.generativeai as genai
from PIL import Image
import speech_recognition as sr
from dotenv import load_dotenv
import os
import time

load_dotenv()
api_key = os.getenv("YOUR_API_KEY")

if not api_key:
    st.error("–ü–æ–º–∏–ª–∫–∞: API –∫–ª—é—á –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π. –í–∫–∞–∂—ñ—Ç—å –∑–º—ñ–Ω–Ω—É —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ YOUR_API_KEY.")
    st.stop()

genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-2.0-flash-exp-image-generation')

languages = {
    "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞": "uk-UA",
    "–ê–Ω–≥–ª—ñ–π—Å—å–∫–∞": "en-US",
    "–ù—ñ–º–µ—Ü—å–∫–∞": "de-DE",
    "–Ü—Å–ø–∞–Ω—Å—å–∫–∞": "es-ES",
    "–§—Ä–∞–Ω—Ü—É–∑—å–∫–∞": "fr-FR",
}

selected_language = st.selectbox("–í–∏–±–µ—Ä—ñ—Ç—å –º–æ–≤—É", list(languages.keys()))

def recognize_speech():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.write("üéôÔ∏è –ì–æ–≤–æ—Ä—ñ—Ç—å...")
        audio = recognizer.listen(source)

    try:
        text = recognizer.recognize_google(audio, language=languages[selected_language])
        st.write(f"‚úÖ –í–∏ —Å–∫–∞–∑–∞–ª–∏: {text}")
        return text
    except sr.UnknownValueError:
        st.write("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –º–æ–≤—É.")
        return None
    except sr.RequestError as e:
        st.write(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–µ—Ä–≤—ñ—Å—É Google Speech Recognition: {e}")
        return None

image_source = st.radio("–í–∏–±–µ—Ä—ñ—Ç—å –¥–∂–µ—Ä–µ–ª–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", ("–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ–∞–π–ª", "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –∫–∞–º–µ—Ä—É"))

image = None
if image_source == "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ–∞–π–ª":
    uploaded_file = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="üì∑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", use_container_width=True)

elif image_source == "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –∫–∞–º–µ—Ä—É":
    picture = st.camera_input("üì∏ –ó—Ä–æ–±—ñ—Ç—å —Ñ–æ—Ç–æ")
    if picture:
        image = Image.open(picture)
        st.image(image, caption="üì∑ –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –∫–∞–º–µ—Ä–∏", use_container_width=True)

if image:
    input_option = st.radio("–í–∏–±–µ—Ä—ñ—Ç—å —Å–ø–æ—Å—ñ–± –≤–≤–µ–¥–µ–Ω–Ω—è –∑–∞–ø–∏—Ç–∞–Ω–Ω—è", ("üìù –í–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç", "üéôÔ∏è –ó–∞–ø–∏—Å–∞—Ç–∏ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è"))

    question = None
    if input_option == "üìù –í–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç":
        question = st.text_input("–í–≤–µ–¥—ñ—Ç—å –≤–∞—à–µ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è")
    else:
        if st.button("üé§ –ó–∞–ø–∏—Å–∞—Ç–∏ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è"):
            question = recognize_speech()

    if question:
        st.write("‚è≥ –ì–µ–Ω–µ—Ä—É—î—Ç—å—Å—è –≤—ñ–¥–ø–æ–≤—ñ–¥—å...")
        response_stream = model.generate_content([question, image], stream=True)

        st.write("üìú **–í—ñ–¥–ø–æ–≤—ñ–¥—å:**")
        placeholder = st.empty()

        response_text = ""
        for chunk in response_stream:
            response_text += chunk.text
            placeholder.write(response_text)
            time.sleep(0.1)